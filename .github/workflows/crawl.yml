name: GitHub Repository Crawler

on:
  workflow_dispatch:  # Manual trigger
  schedule:
    - cron: '0 2 * * *'  # Run daily at 2 AM UTC

jobs:
  crawl:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: github_crawler
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Setup PostgreSQL database
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/github_crawler
      run: |
        python scripts/setup_database.py

    - name: Crawl GitHub repositories
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/github_crawler
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        python src/main.py

    - name: Export data
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/github_crawler
      run: |
        python scripts/export_data.py

    - name: Upload CSV artifact
      uses: actions/upload-artifact@v4
      with:
        name: github-repositories-csv
        path: repositories_export.csv
        retention-days: 30

    - name: Upload JSON artifact
      uses: actions/upload-artifact@v4
      with:
        name: github-repositories-json
        path: repositories_export.json
        retention-days: 30

    - name: Upload database dump (optional)
      uses: actions/upload-artifact@v4
      with:
        name: database-dump
        path: |
          github_crawler.db
        retention-days: 30
      if: always()  # Upload even if previous steps fail
